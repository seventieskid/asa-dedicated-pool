{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "microsoft": {
          "language": "python"
        }
      },
      "outputs": [],
      "source": [
        "%%pyspark\n",
        "df = spark.read.option(\"header\",\"true\").csv('abfss://users@azuron.dfs.core.windows.net/nyc-taxis-2016/*')\n",
        "display(df.count())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "microsoft": {
          "language": "python"
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "%%pyspark\n",
        "spark.sql(\"CREATE DATABASE IF NOT EXISTS new_york\")\n",
        "df.write.mode(\"overwrite\").saveAsTable(\"new_york.tlc_yellow_trips_2016\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "microsoft": {
          "language": "python"
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "%%pyspark\n",
        "df = spark.sql(\"\"\"\n",
        "   SELECT \n",
        "    MIN(dropoff_longitude) min_long, \n",
        "    MAX(dropoff_longitude) max_long,\n",
        "    MIN(dropoff_latitude) min_lat,\n",
        "    MAX(dropoff_latitude) max_lat\n",
        "FROM new_york.tlc_yellow_trips_2016\n",
        "WHERE \n",
        "  ((pickup_latitude BETWEEN -90 AND 90) AND\n",
        "  (pickup_longitude BETWEEN -180 AND 180)) \n",
        "AND\n",
        "  ((dropoff_latitude BETWEEN -90 AND 90) AND\n",
        "  (dropoff_longitude BETWEEN -180 AND 180))\n",
        "\"\"\") \n",
        "display(df)"
      ]
    }
  ],
  "metadata": {
    "description": null,
    "kernel_info": {
      "name": "synapse_pyspark"
    },
    "kernelspec": {
      "display_name": "Synapse PySpark",
      "language": "Python",
      "name": "synapse_pyspark"
    },
    "language_info": {
      "name": "python"
    },
    "save_output": true,
    "synapse_widget": {
      "state": {
        "acc0a4bd-1a7f-4ade-b2d5-4d48a8345fa8": {
          "persist_state": {
            "view": {
              "chartOptions": {
                "aggregationType": "count",
                "categoryFieldKeys": [
                  "0"
                ],
                "chartType": "bar",
                "isStacked": false,
                "seriesFieldKeys": [
                  "0"
                ]
              },
              "tableOptions": {},
              "type": "details"
            }
          },
          "sync_state": {
            "isSummary": false,
            "language": "scala",
            "table": {
              "rows": [
                {
                  "0": "-0.00674699991941452",
                  "1": "38.896591186523438",
                  "2": "-77.03948974609375",
                  "3": "78.5863265991211"
                }
              ],
              "schema": [
                {
                  "key": "0",
                  "name": "min_long",
                  "type": "string"
                },
                {
                  "key": "1",
                  "name": "max_long",
                  "type": "string"
                },
                {
                  "key": "2",
                  "name": "min_lat",
                  "type": "string"
                },
                {
                  "key": "3",
                  "name": "max_lat",
                  "type": "string"
                }
              ],
              "truncated": false
            },
            "wranglerEntryContext": {
              "candidateVariableNames": [
                "df"
              ],
              "dataframeType": "pyspark"
            }
          },
          "type": "Synapse.DataFrame"
        }
      },
      "version": "0.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
